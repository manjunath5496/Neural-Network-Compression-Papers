<h2> Neural Network Compression Papers </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(1).pdf" style="text-decoration:none;">Binarized Neural Networks: Training Neural Networks withWeights and Activations Constrained to +1 or -1</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(2).pdf" style="text-decoration:none;">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(3).pdf" style="text-decoration:none;">Ternary weight networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(4).pdf" style="text-decoration:none;">DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(5).pdf" style="text-decoration:none;">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(6).pdf" style="text-decoration:none;">PACT: Parameterized Clipping Activation for Quantized Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(7).pdf" style="text-decoration:none;">NICE: Noise Injection and Clamping Estimation for Neural Network Quantization</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(8).pdf" style="text-decoration:none;"> BNN+: Improved Binary Network Training </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(9).pdf" style="text-decoration:none;">Matrix and tensor decompositions for training binary neural networks</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(10).pdf" style="text-decoration:none;">Searching for MobileNetV3</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(11).pdf" style="text-decoration:none;">Back to Simplicity: How to Train Accurate BNNs from Scratch?</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(12).pdf" style="text-decoration:none;">And the Bit Goes Down: Revisiting the Quantization of Neural Networks </a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(13).pdf" style="text-decoration:none;">Additive Powers-of-two Quantization: An Efficient Non-uniform Discretization for Neural Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(14).pdf" style="text-decoration:none;">Alternating Multi-bit Quantization for Recurrent Neural Networks</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(15).pdf" style="text-decoration:none;">An empirical study of Binary Neural Networks' Optimisation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(16).pdf" style="text-decoration:none;">Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(17).pdf" style="text-decoration:none;">AutoQ: Automated Kernel-wise Neural Network Quantization</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(18).pdf" style="text-decoration:none;">BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by Coupling Binary Activations</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(19).pdf" style="text-decoration:none;">Deep Learning with Low Precision by Half-wave Gaussian Quantization</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(20).pdf" style="text-decoration:none;">Xception: Deep Learning with Depthwise Separable Convolutions</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(21).pdf" style="text-decoration:none;">Regularizing Activation Distribution for Training Binarized Deep Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(22).pdf" style="text-decoration:none;">LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(23).pdf" style="text-decoration:none;">SYQ: Learning Symmetric Quantization For Efficient Deep Neural Networks</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(24).pdf" style="text-decoration:none;">Network Sketching: Exploiting Binary Structure in Deep CNNs</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(25).pdf" style="text-decoration:none;">Learned Step Quantization</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(26).pdf" style="text-decoration:none;">Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(27).pdf" style="text-decoration:none;">Circulant Binary Convolutional Networks: Enhancing the Performance of 1-bit DCNNs with Circulant Back Propagation</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(28).pdf" style="text-decoration:none;">Model compression via distillation and quantization</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(29).pdf" style="text-decoration:none;">ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(30).pdf" style="text-decoration:none;">Heterogeneous Bitwidth Binarization in Convolutional Neural Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(31).pdf" style="text-decoration:none;">MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(32).pdf" style="text-decoration:none;">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(33).pdf" style="text-decoration:none;">Towards Accurate Binary Convolutional Neural Network</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(34).pdf" style="text-decoration:none;">Weighted-Entropy-based Quantization for Deep Neural Networks</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(35).pdf" style="text-decoration:none;">ProxQuant: Quantized Neural Networks via Proximal Operators</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(36).pdf" style="text-decoration:none;">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(37).pdf" style="text-decoration:none;">Slimmable Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(38).pdf" style="text-decoration:none;">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(39).pdf" style="text-decoration:none;">Trained Ternary Quantization</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(40).pdf" style="text-decoration:none;">Training and Inference with Integers in Deep Neural Networks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(41).pdf" style="text-decoration:none;">Training Binary Neural Networks with Real-to-Binary Convolutions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(42).pdf" style="text-decoration:none;">StrassenNets: Deep Learning with a Multiplication Budget</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(43).pdf" style="text-decoration:none;">Learning Channel-wise Interactions for Binary Convolutional Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(44).pdf" style="text-decoration:none;">Two-Step Quantization for Low-bit Neural Networks</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(45).pdf" style="text-decoration:none;">WRPN: Wide Reduced-Precision Networks</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(46).pdf" style="text-decoration:none;">Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(47).pdf" style="text-decoration:none;">A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(48).pdf" style="text-decoration:none;">Quantization Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(49).pdf" style="text-decoration:none;">Bi-Real Net: Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(50).pdf" style="text-decoration:none;">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(51).pdf" style="text-decoration:none;">Binary Ensemble Neural Network: More Bits per Network or More Networks per Bit?</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(52).pdf" style="text-decoration:none;">Structured Binary Neural Networks for Accurate Image Classification and Semantic Segmentation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(53).pdf" style="text-decoration:none;">Towards Effective Low-bitwidth Convolutional Neural Networks</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Neural-Network-Compression-Papers/blob/master/ncn(54).pdf" style="text-decoration:none;">All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification </a></li>

</ul>
